{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Zhifang\n",
      "[nltk_data]     Xie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Zhifang\n",
      "[nltk_data]     Xie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Zhifang\n",
      "[nltk_data]     Xie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import spacy, nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from textblob import Blobber\n",
    "\n",
    "from sklearn import metrics\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE, BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_data = pd.read_csv('cons_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>cons</th>\n",
       "      <th>facility_ind</th>\n",
       "      <th>security_ind</th>\n",
       "      <th>pricing_ind</th>\n",
       "      <th>location_ind</th>\n",
       "      <th>fb_ind</th>\n",
       "      <th>housekeep_ind</th>\n",
       "      <th>frontoff_ind</th>\n",
       "      <th>others</th>\n",
       "      <th>pos_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bedroom very bland</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>no soft furnishings</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>too little furniture in a big space</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>uncomfortable couch area and needs colour or i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>hotel could do with a residents bar for a rela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number                                               cons  \\\n",
       "0              0                                 bedroom very bland   \n",
       "1              0                                no soft furnishings   \n",
       "2              0                too little furniture in a big space   \n",
       "3              0  uncomfortable couch area and needs colour or i...   \n",
       "4              0  hotel could do with a residents bar for a rela...   \n",
       "\n",
       "   facility_ind  security_ind  pricing_ind  location_ind  fb_ind  \\\n",
       "0             1             0            0             0       0   \n",
       "1             1             0            0             0       0   \n",
       "2             1             0            0             0       0   \n",
       "3             1             0            0             0       0   \n",
       "4             0             0            0             0       1   \n",
       "\n",
       "   housekeep_ind  frontoff_ind others  pos_ind  \n",
       "0              0             0      0        0  \n",
       "1              0             0      0        0  \n",
       "2              0             0      0        0  \n",
       "3              0             0      0        0  \n",
       "4              0             0      0        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8139, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_number    0\n",
       "cons             1\n",
       "facility_ind     0\n",
       "security_ind     0\n",
       "pricing_ind      0\n",
       "location_ind     0\n",
       "fb_ind           0\n",
       "housekeep_ind    0\n",
       "frontoff_ind     0\n",
       "others           0\n",
       "pos_ind          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8138, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_data.dropna(subset=['cons'], inplace=True)\n",
    "cons_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8138 entries, 0 to 8138\n",
      "Data columns (total 11 columns):\n",
      "review_number    8138 non-null int64\n",
      "cons             8138 non-null object\n",
      "facility_ind     8138 non-null int64\n",
      "security_ind     8138 non-null int64\n",
      "pricing_ind      8138 non-null int64\n",
      "location_ind     8138 non-null int64\n",
      "fb_ind           8138 non-null int64\n",
      "housekeep_ind    8138 non-null int64\n",
      "frontoff_ind     8138 non-null int64\n",
      "others           8138 non-null object\n",
      "pos_ind          8138 non-null int64\n",
      "dtypes: int64(9), object(2)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "cons_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = cons_data.cons\n",
    "corpus = corpus.str.lower().apply(lambda x: str(x).encode('ascii', errors='ignore').decode())\n",
    "corpus = corpus.replace(r'http\\S+', ' ', regex=True)\n",
    "corpus = corpus.replace(r'[^A-Za-z]', ' ', regex=True)\n",
    "corpus = corpus.replace(r' ', np.nan).dropna()\n",
    "corpus = corpus.astype(str).apply(nltk.word_tokenize)\n",
    "lemma = nltk.WordNetLemmatizer() \n",
    "corpus = corpus.apply(lambda x: ' '.join([lemma.lemmatize(word) for word in x]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8117,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_number</th>\n",
       "      <th>cons</th>\n",
       "      <th>facility_ind</th>\n",
       "      <th>security_ind</th>\n",
       "      <th>pricing_ind</th>\n",
       "      <th>location_ind</th>\n",
       "      <th>fb_ind</th>\n",
       "      <th>housekeep_ind</th>\n",
       "      <th>frontoff_ind</th>\n",
       "      <th>others</th>\n",
       "      <th>pos_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bedroom very bland</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>no soft furnishings</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>too little furniture in a big space</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>uncomfortable couch area and needs colour or i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>hotel could do with a residents bar for a rela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_number                                               cons  \\\n",
       "0              0                                 bedroom very bland   \n",
       "1              0                                no soft furnishings   \n",
       "2              0                too little furniture in a big space   \n",
       "3              0  uncomfortable couch area and needs colour or i...   \n",
       "4              0  hotel could do with a residents bar for a rela...   \n",
       "\n",
       "   facility_ind  security_ind  pricing_ind  location_ind  fb_ind  \\\n",
       "0             1             0            0             0       0   \n",
       "1             1             0            0             0       0   \n",
       "2             1             0            0             0       0   \n",
       "3             1             0            0             0       0   \n",
       "4             0             0            0             0       1   \n",
       "\n",
       "   housekeep_ind  frontoff_ind others  pos_ind  \n",
       "0              0             0      0        0  \n",
       "1              0             0      0        0  \n",
       "2              0             0      0        0  \n",
       "3              0             0      0        0  \n",
       "4              0             0      0        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cons_data[cons_data.index.isin(corpus.index)].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7722\n",
       "1     395\n",
       "Name: pos_ind, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pos_ind.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg_ind'] = 1 - df.pos_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.2, stratify=df.neg_ind, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.cons\n",
    "y_train = train.neg_ind\n",
    "X_val = val.cons\n",
    "y_val = val.neg_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "nltk_scores_train = train.cons.map(sid.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set f1 score using NLTK sentiment analysis:  0.8497257769652651\n"
     ]
    }
   ],
   "source": [
    "nltk_scores = val.cons.map(sid.polarity_scores)\n",
    "nltk_ind = nltk_scores.apply(lambda x: 0 if x.get('compound')>0.05 else 1)\n",
    "print('Validation set f1 score using NLTK sentiment analysis: ', metrics.f1_score(val.neg_ind, nltk_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  51   28]\n",
      " [ 383 1162]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.65      0.20        79\n",
      "           1       0.98      0.75      0.85      1545\n",
      "\n",
      "    accuracy                           0.75      1624\n",
      "   macro avg       0.55      0.70      0.52      1624\n",
      "weighted avg       0.93      0.75      0.82      1624\n",
      "\n",
      "ROC_AUC score:  0.6988365900618573\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n', metrics.confusion_matrix(y_val, nltk_ind))\n",
    "print('Classification report: \\n', metrics.classification_report(y_val, nltk_ind))\n",
    "print('ROC_AUC score: ', metrics.roc_auc_score(y_val, nltk_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set f1 score using TextBlob sentiment analysis:  0.7983257229832572\n"
     ]
    }
   ],
   "source": [
    "textblob_scores = val.cons.apply(lambda x: TextBlob(x).sentiment)\n",
    "textblob_ind = textblob_scores.apply(lambda x: 0 if x.polarity>0.05 else 1)\n",
    "print('Validation set f1 score using TextBlob sentiment analysis: ', metrics.f1_score(val.neg_ind, textblob_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  45   34]\n",
      " [ 496 1049]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.57      0.15        79\n",
      "           1       0.97      0.68      0.80      1545\n",
      "\n",
      "    accuracy                           0.67      1624\n",
      "   macro avg       0.53      0.62      0.47      1624\n",
      "weighted avg       0.93      0.67      0.77      1624\n",
      "\n",
      "ROC_AUC score:  0.6242923272295275\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n', metrics.confusion_matrix(y_val, textblob_ind))\n",
    "print('Classification report: \\n', metrics.classification_report(y_val, textblob_ind))\n",
    "print('ROC_AUC score: ', metrics.roc_auc_score(y_val, textblob_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob (NB analyzer) Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set f1 score using Textblob (NB Analyzer) Sentiment Analysis:  0.5132075471698112\n"
     ]
    }
   ],
   "source": [
    "blobbernb_scores = val.cons.apply(lambda x: tb(x).sentiment.classification)\n",
    "blobbernb_ind = blobbernb_scores.map({'pos':0, 'neg':1})\n",
    "print('Validation set f1 score using Textblob (NB Analyzer) Sentiment Analysis: ', metrics.f1_score(val.neg_ind, blobbernb_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  48   31]\n",
      " [1001  544]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.61      0.09        79\n",
      "           1       0.95      0.35      0.51      1545\n",
      "\n",
      "    accuracy                           0.36      1624\n",
      "   macro avg       0.50      0.48      0.30      1624\n",
      "weighted avg       0.90      0.36      0.49      1624\n",
      "\n",
      "ROC_AUC score:  0.4798492482897055\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n', metrics.confusion_matrix(y_val, blobbernb_ind))\n",
    "print('Classification report: \\n', metrics.classification_report(y_val, blobbernb_ind))\n",
    "print('ROC_AUC score: ', metrics.roc_auc_score(y_val, blobbernb_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()\n",
    "ros = RandomOverSampler()\n",
    "smote = SMOTE(kind='regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "lr = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for RandomUnderSampling:  0.9562918945902323\n",
      "Validation set f1-score for RandomUnderSampling:  0.9577371048252913\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', tfidf_vect),('rus', rus),('lr', lr)])\n",
    "cv_score = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=5).mean()\n",
    "print('Cross validation score for RandomUnderSampling: ', cv_score)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_val)\n",
    "val_score = metrics.f1_score(y_val, y_pred)\n",
    "print('Validation set f1-score for RandomUnderSampling: ', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for RandomOverSampling:  0.9717413992287985\n",
      "Validation set f1-score for RandomOverSampling:  0.9676994067237971\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', tfidf_vect),('ros', ros),('lr', lr)])\n",
    "cv_score = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=5).mean()\n",
    "print('Cross validation score for RandomOverSampling: ', cv_score)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_val)\n",
    "val_score = metrics.f1_score(y_val, y_pred)\n",
    "print('Validation set f1-score for RandomOverSampling: ', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for SMOTE:  0.9726273081226958\n",
      "Validation set f1-score for SMOTE:  0.9707525468287873\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', tfidf_vect),('smote', smote),('lr', lr)])\n",
    "cv_score = cross_val_score(pipe, X_train, y_train, scoring='f1', cv=5).mean()\n",
    "print('Cross validation score for SMOTE: ', cv_score)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_val)\n",
    "val_score = metrics.f1_score(y_val, y_pred)\n",
    "print('Validation set f1-score for SMOTE: ', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = [(1,1),(1,2),(1,3),(2,2),(2,3)]\n",
    "use_idf = [True, False]\n",
    "C = [0.01,0.1,1,10,100]\n",
    "b_model = None\n",
    "b_score = 0\n",
    "\n",
    "for (nr, ui, c) in [(nr, ui, c) for nr in ngram_range for ui in use_idf for c in C]:\n",
    "    tfidf_vect = TfidfVectorizer(ngram_range=nr, use_idf=ui)\n",
    "    smote = SMOTE(sampling_strategy=1, kind='regular')\n",
    "    lr = LogisticRegression(C=c, max_iter=1000)\n",
    "    pipe = Pipeline([('tfidf', tfidf_vect),('smote', smote),('lr', lr)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    val_score = metrics.f1_score(y_val, y_pred)\n",
    "    if val_score > b_score:\n",
    "        b_score = val_score\n",
    "        b_model = pipe\n",
    "        b_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set f1 score from the best model:  0.9812297734627832\n",
      "Best parameters: \n",
      "ngram_range: (1, 3)\n",
      "use_idf: False\n",
      "C: 100\n"
     ]
    }
   ],
   "source": [
    "print('Validation set f1 score from the best model: ', b_score)\n",
    "print('Best parameters: ')\n",
    "print('ngram_range:',b_model.get_params()['tfidf__ngram_range'])\n",
    "print('use_idf:', b_model.get_params()['tfidf__use_idf'])\n",
    "print('C:',b_model.get_params()['lr__C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  50   29]\n",
      " [  29 1516]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63        79\n",
      "           1       0.98      0.98      0.98      1545\n",
      "\n",
      "    accuracy                           0.96      1624\n",
      "   macro avg       0.81      0.81      0.81      1624\n",
      "weighted avg       0.96      0.96      0.96      1624\n",
      "\n",
      "ROC_AUC score:  0.8070705829339232\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n', metrics.confusion_matrix(y_val, b_pred))\n",
    "print('Classification report: \\n', metrics.classification_report(y_val, b_pred)) \n",
    "print('ROC_AUC score: ', metrics.roc_auc_score(y_val, b_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_ind = pd.DataFrame(np.column_stack((b_pred, nltk_ind, textblob_ind)),columns=['LR model', 'NLTK', 'TextBlob']).mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set f1 score from ensemble model:  0.9026178010471204\n"
     ]
    }
   ],
   "source": [
    "print('Validation set f1 score from ensemble model: ', metrics.f1_score(y_val, sentiment_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[  52   27]\n",
      " [ 252 1293]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.66      0.27        79\n",
      "           1       0.98      0.84      0.90      1545\n",
      "\n",
      "    accuracy                           0.83      1624\n",
      "   macro avg       0.58      0.75      0.59      1624\n",
      "weighted avg       0.94      0.83      0.87      1624\n",
      "\n",
      "ROC_AUC score:  0.7475605259923804\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix: \\n', metrics.confusion_matrix(y_val, sentiment_ind))\n",
    "print('Classification report: \\n', metrics.classification_report(y_val, sentiment_ind))\n",
    "print('ROC_AUC score: ', metrics.roc_auc_score(y_val, sentiment_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('pos_ind', axis=1, inplace=True)\n",
    "df.to_csv('data_sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
